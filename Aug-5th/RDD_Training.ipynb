{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-13hjmtsbNZf"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('RDDExamples').master(\"local[*]\").getOrCreate()\n",
        "\n",
        "sc=spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nums=sc.parallelize([1,2,3,4,5])"
      ],
      "metadata": {
        "id": "Py5j_v2cbuTM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nums.collect())\n",
        "print(nums.count())\n",
        "nums.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swbtYW74cCWW",
        "outputId": "244b80a3-2281-4e9b-e98a-45a703bf2e1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5]\n",
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squares=nums.map(lambda x:x*x)\n",
        "even_squares=squares.filter(lambda x:x%2==0)\n",
        "even_squares.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg4I9WcGiT9v",
        "outputId": "00cb04f8-dc22-43bb-abfb-4f17c62eb33f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 16]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines=sc.parallelize([\n",
        "    'spark makes big data simple',\n",
        "    'rdds are resilient distributed dataset',\n",
        "    'spark runs tes'\n",
        "])\n",
        "\n",
        "word_counts=(lines\n",
        "         .flatMap(lambda line:line\n",
        "         .split(' ')).map(lambda word:(word,1))\n",
        "         .reduceByKey(lambda a,b:a+b))\n",
        "\n",
        "word_counts.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpljQi30lltn",
        "outputId": "a035437b-2822-4b48-fb33-24c924131952"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('big', 1),\n",
              " ('are', 1),\n",
              " ('resilient', 1),\n",
              " ('distributed', 1),\n",
              " ('dataset', 1),\n",
              " ('runs', 1),\n",
              " ('tes', 1),\n",
              " ('spark', 2),\n",
              " ('makes', 1),\n",
              " ('data', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}