{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. PySpark Setup & Initialization**\n",
        "\n",
        "Exercise 1.1 – Setup Spark:"
      ],
      "metadata": {
        "id": "GYrv5PkSyoDd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CxqOuyPkyYTn"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"BotCampus Intermediate Session\") \\\n",
        ".master(\"local[*]\") \\\n",
        ".getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1.2 – Load starter data:"
      ],
      "metadata": {
        "id": "wvkfvcG7yxsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Ananya\", \"Bangalore\", 24),\n",
        "(\"Ravi\", \"Hyderabad\", 28),\n",
        "(\"Kavya\", \"Delhi\", 22),\n",
        "(\"Meena\", \"Chennai\", 25)]\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7C-NMOky0mb",
        "outputId": "a3885706-97c3-4b30-9513-da958c8ba17d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---+\n",
            "|  name|     city|age|\n",
            "+------+---------+---+\n",
            "|Ananya|Bangalore| 24|\n",
            "|  Ravi|Hyderabad| 28|\n",
            "| Kavya|    Delhi| 22|\n",
            "| Meena|  Chennai| 25|\n",
            "+------+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. RDDs & Transformations**\n",
        "\n",
        "Exercise 2.1 – Create RDD from feedback:"
      ],
      "metadata": {
        "id": "9diH8MYSzAhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback = spark.sparkContext.parallelize([\n",
        "\"Ravi from Bangalore loved the mobile app\",\n",
        "\"Meena from Delhi reported poor response time\",\n",
        "\"Ajay from Pune liked the delivery speed\",\n",
        "\"Ananya from Hyderabad had an issue with UI\",\n",
        "\"Rohit from Mumbai gave positive feedback\"\n",
        "])"
      ],
      "metadata": {
        "id": "ZIYRdGzDzGkj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tasks:**\n",
        "\n",
        "Count total number of words."
      ],
      "metadata": {
        "id": "20PmuX_NzNO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback.flatMap(lambda x: x.split()).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhouLWM_zXTW",
        "outputId": "b756bd04-74bb-4f6f-b916-d23648c366ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find top 3 most common words."
      ],
      "metadata": {
        "id": "a9c9wpHXzzIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback.flatMap(lambda x: x.split()).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).takeOrdered(3, key=lambda x: -x[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxS0NDOmz-8h",
        "outputId": "c476f668-003a-4b9e-88a7-d94ef447d449"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('from', 5), ('the', 2), ('loved', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove stop words ( from , with , the , etc.)."
      ],
      "metadata": {
        "id": "Hi995LW_0Wye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback.flatMap(lambda x: x.split()).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).filter(lambda x: x[0] not in [\"from\", \"with\", \"the\", \"had\", \"an\", \"a\", \"of\", \"and\", \"in\", \"to\"]).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RUsA4UP0Y2V",
        "outputId": "5d0faf33-c9f7-489f-87ba-e19b55c67942"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('loved', 1),\n",
              " ('app', 1),\n",
              " ('Delhi', 1),\n",
              " ('poor', 1),\n",
              " ('response', 1),\n",
              " ('Ajay', 1),\n",
              " ('Pune', 1),\n",
              " ('liked', 1),\n",
              " ('speed', 1),\n",
              " ('Hyderabad', 1),\n",
              " ('issue', 1),\n",
              " ('UI', 1),\n",
              " ('Rohit', 1),\n",
              " ('Mumbai', 1),\n",
              " ('positive', 1),\n",
              " ('feedback', 1),\n",
              " ('Ravi', 1),\n",
              " ('Bangalore', 1),\n",
              " ('mobile', 1),\n",
              " ('Meena', 1),\n",
              " ('reported', 1),\n",
              " ('time', 1),\n",
              " ('delivery', 1),\n",
              " ('Ananya', 1),\n",
              " ('gave', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a dictionary of word → count."
      ],
      "metadata": {
        "id": "FkIoQwZZ12QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback.flatMap(lambda x: x.split()).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).collectAsMap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvfK5GzB14uT",
        "outputId": "9757dbab-6467-4972-dcd7-95bab9a0eba8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'from': 5,\n",
              " 'loved': 1,\n",
              " 'app': 1,\n",
              " 'Delhi': 1,\n",
              " 'poor': 1,\n",
              " 'response': 1,\n",
              " 'Ajay': 1,\n",
              " 'Pune': 1,\n",
              " 'liked': 1,\n",
              " 'speed': 1,\n",
              " 'Hyderabad': 1,\n",
              " 'an': 1,\n",
              " 'issue': 1,\n",
              " 'with': 1,\n",
              " 'UI': 1,\n",
              " 'Rohit': 1,\n",
              " 'Mumbai': 1,\n",
              " 'positive': 1,\n",
              " 'feedback': 1,\n",
              " 'Ravi': 1,\n",
              " 'Bangalore': 1,\n",
              " 'the': 2,\n",
              " 'mobile': 1,\n",
              " 'Meena': 1,\n",
              " 'reported': 1,\n",
              " 'time': 1,\n",
              " 'delivery': 1,\n",
              " 'Ananya': 1,\n",
              " 'had': 1,\n",
              " 'gave': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. DataFrames – Transformations**\n",
        "\n",
        "Exercise 3.1 – Create exam_scores DataFrame:"
      ],
      "metadata": {
        "id": "o5aQQzLr3QJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = [\n",
        "(\"Ravi\", \"Math\", 88),\n",
        "(\"Ananya\", \"Science\", 92),\n",
        "(\"Kavya\", \"English\", 79),\n",
        "(\"Ravi\", \"English\", 67),\n",
        "(\"Neha\", \"Math\", 94),\n",
        "(\"Meena\", \"Science\", 85)\n",
        "]\n",
        "\n",
        "columns = [\"name\", \"subject\", \"score\"]\n",
        "df_scores = spark.createDataFrame(scores, columns)"
      ],
      "metadata": {
        "id": "zSsgXfZ83TwH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks:\n",
        "\n",
        "Add grade column ( >=90 → A, 80-89 → B, 70-79 → C, else D)."
      ],
      "metadata": {
        "id": "O8SPdt553swk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "df_scores=df_scores.withColumn(\"grade\",F.when(df_scores[\"score\"]>=90,\"A\").when((df_scores[\"score\"]>=80) & (df_scores[\"score\"]<90),\"B\").when((df_scores[\"score\"]>=70)&(df_scores[\"score\"]<80),\"C\").otherwise(\"D\"))\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWme5A_Y3yq4",
        "outputId": "c3e62fb0-9f2e-414d-e17f-b00aca6e3c5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+\n",
            "|  name|subject|score|grade|\n",
            "+------+-------+-----+-----+\n",
            "|  Ravi|   Math|   88|    B|\n",
            "|Ananya|Science|   92|    A|\n",
            "| Kavya|English|   79|    C|\n",
            "|  Ravi|English|   67|    D|\n",
            "|  Neha|   Math|   94|    A|\n",
            "| Meena|Science|   85|    B|\n",
            "+------+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group by subject, find average score."
      ],
      "metadata": {
        "id": "LHWYYsBC5BeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores.groupBy(\"subject\").avg(\"score\").alias(\"avg_score\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRbvOF_P5D3c",
        "outputId": "ff54643d-1701-4b8f-bf09-a307b88e4f4c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|subject|avg(score)|\n",
            "+-------+----------+\n",
            "|Science|      88.5|\n",
            "|   Math|      91.0|\n",
            "|English|      73.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use when and otherwise to classify subject difficulty ( Math/Science =\n",
        "Difficult)."
      ],
      "metadata": {
        "id": "BI6Fm1mO5OmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores=df_scores.withColumn(\"difficulty\",F.when(df_scores.subject.isin([\"Math\",\"Science\"]),\"Difficult\").otherwise(\"Easy\"))\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRp3BMHh5RVC",
        "outputId": "3447f78e-e6ff-4d7e-a829-b8e14ddddb5e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+\n",
            "|  name|subject|score|grade|difficulty|\n",
            "+------+-------+-----+-----+----------+\n",
            "|  Ravi|   Math|   88|    B| Difficult|\n",
            "|Ananya|Science|   92|    A| Difficult|\n",
            "| Kavya|English|   79|    C|      Easy|\n",
            "|  Ravi|English|   67|    D|      Easy|\n",
            "|  Neha|   Math|   94|    A| Difficult|\n",
            "| Meena|Science|   85|    B| Difficult|\n",
            "+------+-------+-----+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rank students per subject using Window function."
      ],
      "metadata": {
        "id": "xIusUh4B54sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "windowSpec = Window.partitionBy(\"subject\").orderBy(F.desc(\"score\"))\n",
        "df_scores.withColumn(\"rank\",F.rank().over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3e8WDLb57Xs",
        "outputId": "74505815-8ebe-4824-eacb-8145457c1dbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+----+\n",
            "|  name|subject|score|grade|difficulty|rank|\n",
            "+------+-------+-----+-----+----------+----+\n",
            "| Kavya|English|   79|    C|      Easy|   1|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|\n",
            "|Ananya|Science|   92|    A| Difficult|   1|\n",
            "| Meena|Science|   85|    B| Difficult|   2|\n",
            "+------+-------+-----+-----+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply UDF to format names (e.g., make all uppercase)."
      ],
      "metadata": {
        "id": "4qD16X1r8O8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def upper_name(name):\n",
        "    return name.upper()\n",
        "\n",
        "upper_udf = udf(upper_name, StringType())\n",
        "df_scores=df_scores.withColumn(\"name\", upper_udf(df_scores[\"name\"]))\n",
        "df_scores.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqq8urJ_8RIf",
        "outputId": "0f6c1f00-4842-4765-bf85-0586b64c18e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+\n",
            "|  name|subject|score|grade|difficulty|\n",
            "+------+-------+-----+-----+----------+\n",
            "|  RAVI|   Math|   88|    B| Difficult|\n",
            "|ANANYA|Science|   92|    A| Difficult|\n",
            "| KAVYA|English|   79|    C|      Easy|\n",
            "|  RAVI|English|   67|    D|      Easy|\n",
            "|  NEHA|   Math|   94|    A| Difficult|\n",
            "| MEENA|Science|   85|    B| Difficult|\n",
            "+------+-------+-----+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Ingest CSV & JSON – Save to Parquet**\n",
        "\n",
        "Dataset 1: CSV file: students.csv"
      ],
      "metadata": {
        "id": "UlwB_h6M-GEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=\"\"\"id,name,department,city,salary\n",
        "1,Amit,IT,Bangalore,78000\n",
        "2,Kavya,HR,Chennai,62000\n",
        "3,Arjun,Finance,Hyderabad,55000\"\"\"\n",
        "\n",
        "with open(\"students.csv\", \"w\") as f:\n",
        "    f.write(data)"
      ],
      "metadata": {
        "id": "fg-rnm0Z-Pzt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 2: JSON file employee_nested.json"
      ],
      "metadata": {
        "id": "mVAvDnfTBHil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "data=[{\n",
        "\"id\": 101,\n",
        "\"name\": \"Sneha\",\n",
        "\"address\": {\n",
        "\"city\": \"Mumbai\",\n",
        "\"pincode\": 400001\n",
        "},\n",
        "\"skills\": [\"Python\", \"Spark\"]\n",
        "}\n",
        "]\n",
        "\n",
        "with open(\"employee_nested.json\", \"w\") as f:\n",
        "    json.dump(data, f)\n",
        "\n"
      ],
      "metadata": {
        "id": "nw-riiSxBJPy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv=spark.read.csv(\"students.csv\",header=True)\n",
        "df_csv.show()\n",
        "\n",
        "df_json=spark.read.json(\"employee_nested.json\")\n",
        "df_json.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir7z5ZE4BYnR",
        "outputId": "de8a763e-b033-4e3a-da8e-e69cb2a7b655"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+---------+------+\n",
            "| id| name|department|     city|salary|\n",
            "+---+-----+----------+---------+------+\n",
            "|  1| Amit|        IT|Bangalore| 78000|\n",
            "|  2|Kavya|        HR|  Chennai| 62000|\n",
            "|  3|Arjun|   Finance|Hyderabad| 55000|\n",
            "+---+-----+----------+---------+------+\n",
            "\n",
            "+----------------+---+-----+---------------+\n",
            "|         address| id| name|         skills|\n",
            "+----------------+---+-----+---------------+\n",
            "|{Mumbai, 400001}|101|Sneha|[Python, Spark]|\n",
            "+----------------+---+-----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print schema and infer nested structure."
      ],
      "metadata": {
        "id": "kcTqmCfMBdrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.printSchema()\n",
        "df_json.printSchema()\n",
        "df_json.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gURzFI5oBf9U",
        "outputId": "cafc4d0d-4018-4d20-de94-f6fc9b3bc2ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- pincode: long (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- skills: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+----------------+---+-----+---------------+\n",
            "|address         |id |name |skills         |\n",
            "+----------------+---+-----+---------------+\n",
            "|{Mumbai, 400001}|101|Sneha|[Python, Spark]|\n",
            "+----------------+---+-----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten the JSON (use explode , select , alias )."
      ],
      "metadata": {
        "id": "C8DierokBvbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_flat=df_json.select(F.col(\"id\"),F.col(\"name\"),F.col('address.city').alias(\"city\"),F.col('address.pincode').alias(\"pincode\"),F.explode(F.col(\"skills\")).alias(\"skill\"))\n",
        "df_flat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVlAUI-yBx1h",
        "outputId": "cd9a19b1-ec2c-4d6f-a4e0-605c962e251b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+------+-------+------+\n",
            "| id| name|  city|pincode| skill|\n",
            "+---+-----+------+-------+------+\n",
            "|101|Sneha|Mumbai| 400001|Python|\n",
            "|101|Sneha|Mumbai| 400001| Spark|\n",
            "+---+-----+------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert both to Parquet and write to /tmp/output"
      ],
      "metadata": {
        "id": "IVKYODxNCaKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.write.parquet(\"/tmp/output/students.parquet\")\n",
        "df_flat.write.parquet(\"/tmp/output/employee_nested.parquet\")"
      ],
      "metadata": {
        "id": "rpL8fSsfCiT1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Spark SQL – Temp Views & Queries**\n",
        "\n",
        "Exercise 5.1 Create view from exam scores and run:"
      ],
      "metadata": {
        "id": "i6H2z73KCof9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores.show()\n",
        "df_scores.createOrReplaceTempView(\"exam_scores\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bmJ64OiCwLj",
        "outputId": "be7bf773-df23-4f68-9b56-dea97d7e038c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+\n",
            "|  name|subject|score|grade|difficulty|\n",
            "+------+-------+-----+-----+----------+\n",
            "|  RAVI|   Math|   88|    B| Difficult|\n",
            "|ANANYA|Science|   92|    A| Difficult|\n",
            "| KAVYA|English|   79|    C|      Easy|\n",
            "|  RAVI|English|   67|    D|      Easy|\n",
            "|  NEHA|   Math|   94|    A| Difficult|\n",
            "| MEENA|Science|   85|    B| Difficult|\n",
            "+------+-------+-----+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Top scorer per subject"
      ],
      "metadata": {
        "id": "OVPb-RglC6VU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select name,subject,score from exam_scores where (subject,score) in (select subject,max(score) from exam_scores group by subject)\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXIVvA3AC9Do",
        "outputId": "5c8b71cf-8990-4db8-a9d2-9c532c5827a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+\n",
            "|  name|subject|score|\n",
            "+------+-------+-----+\n",
            "|ANANYA|Science|   92|\n",
            "| KAVYA|English|   79|\n",
            "|  NEHA|   Math|   94|\n",
            "+------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Count of students per grade"
      ],
      "metadata": {
        "id": "mFKJ2MRuDMLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select grade,count(*) as count from exam_scores group by grade\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa0MSqT1DPIX",
        "outputId": "a4616a29-5a27-4a37-b4d7-6f8af9a76300"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|grade|count|\n",
            "+-----+-----+\n",
            "|    B|    2|\n",
            "|    C|    1|\n",
            "|    A|    2|\n",
            "|    D|    1|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Students with multiple subjects"
      ],
      "metadata": {
        "id": "m39B-uagDktZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select name,count(subject) as Count from exam_scores group by name having count>1\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Linq6aPhDm4i",
        "outputId": "b8febb4a-7a4c-4e40-a458-fb7760463e68"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|name|Count|\n",
            "+----+-----+\n",
            "|RAVI|    2|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Subjects with average score above 85"
      ],
      "metadata": {
        "id": "p2p3V3ELEFJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select subject,avg(score) as avg_score from exam_scores group by subject having avg_score>85\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1eNfOcHEIny",
        "outputId": "3b10b25d-879f-4240-c598-502b06046894"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|subject|avg_score|\n",
            "+-------+---------+\n",
            "|Science|     88.5|\n",
            "|   Math|     91.0|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 5.2 Create another DataFrame attendance(name, days_present) and:"
      ],
      "metadata": {
        "id": "ZHtrmFEoEkyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attendance = [(\"RAVI\", 25), (\"ANANYA\", 18), (\"KAVYA\", 22), (\"NEHA\", 19), (\"MEENA\", 20)]\n",
        "df_attendance = spark.createDataFrame(attendance, [\"name\", \"days_present\"])\n",
        "df_attendance.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyqqeFJcEn3Y",
        "outputId": "55e2a4fd-adff-4685-9a62-cfe2942a1bfc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+\n",
            "|  name|days_present|\n",
            "+------+------------+\n",
            "|  RAVI|          25|\n",
            "|ANANYA|          18|\n",
            "| KAVYA|          22|\n",
            "|  NEHA|          19|\n",
            "| MEENA|          20|\n",
            "+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join with scores"
      ],
      "metadata": {
        "id": "MaqvE1cEG9aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_attendance.createOrReplaceTempView(\"attendance\")\n",
        "df_scores.createOrReplaceTempView(\"exam_scores\")\n",
        "df_merge=spark.sql(\"select e.name,e.subject,e.score,e.grade,e.difficulty,a.days_present from exam_scores e join attendance  a on e.name=a.name\")\n",
        "df_merge.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGE85Up8G_2R",
        "outputId": "47bd0fc6-9d94-4490-d357-673ba6bd7c3b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+------------+\n",
            "|  name|subject|score|grade|difficulty|days_present|\n",
            "+------+-------+-----+-----+----------+------------+\n",
            "|ANANYA|Science|   92|    A| Difficult|          18|\n",
            "| KAVYA|English|   79|    C|      Easy|          22|\n",
            "| MEENA|Science|   85|    B| Difficult|          20|\n",
            "|  NEHA|   Math|   94|    A| Difficult|          19|\n",
            "|  RAVI|   Math|   88|    B| Difficult|          25|\n",
            "|  RAVI|English|   67|    D|      Easy|          25|\n",
            "+------+-------+-----+-----+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate attendance-adjusted grade:\n",
        "\n",
        "If days_present < 20 → downgrade grade by one level"
      ],
      "metadata": {
        "id": "zBOaCAFgJGag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grade_order = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4}\n",
        "reverse_grade_order = {v: k for k, v in grade_order.items()}\n",
        "\n",
        "def downgrade_grade(grade, days):\n",
        "    if days is None:\n",
        "        return grade\n",
        "    order = grade_order.get(grade, 4)\n",
        "    if days < 20 and order < 4:\n",
        "        order += 1\n",
        "    return reverse_grade_order.get(order, grade)\n",
        "\n",
        "downgrade_udf = udf(downgrade_grade, StringType())\n",
        "df_merge=df_merge.withColumn(\"adjusted_grade\",downgrade_udf(df_merge[\"grade\"],df_merge[\"days_present\"]))\n",
        "df_merge.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu5_g1OFJK9t",
        "outputId": "25824094-3ec8-4211-ed4b-4f5a42a0f1ba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+----------+------------+--------------+\n",
            "|  name|subject|score|grade|difficulty|days_present|adjusted_grade|\n",
            "+------+-------+-----+-----+----------+------------+--------------+\n",
            "|ANANYA|Science|   92|    A| Difficult|          18|             B|\n",
            "| KAVYA|English|   79|    C|      Easy|          22|             C|\n",
            "| MEENA|Science|   85|    B| Difficult|          20|             B|\n",
            "|  NEHA|   Math|   94|    A| Difficult|          19|             B|\n",
            "|  RAVI|   Math|   88|    B| Difficult|          25|             B|\n",
            "|  RAVI|English|   67|    D|      Easy|          25|             D|\n",
            "+------+-------+-----+-----+----------+------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Partitioned Load (Full + Incremental)**\n",
        "\n",
        "Initial Load:"
      ],
      "metadata": {
        "id": "LpI6Q6dXU9fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores.write.partitionBy(\"subject\").parquet(\"/tmp/scores/\")"
      ],
      "metadata": {
        "id": "a90HfKjgVEdE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incremental Load:"
      ],
      "metadata": {
        "id": "t2gglqvPVHQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incremental = [(\"Meena\", \"Math\", 93)]\n",
        "df_inc = spark.createDataFrame(incremental, columns)\n",
        "df_inc.write.mode(\"append\").partitionBy(\"subject\").parquet(\"/tmp/scores/\")"
      ],
      "metadata": {
        "id": "ENzTJHVsVK4w"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List all folders inside /tmp/scores/"
      ],
      "metadata": {
        "id": "qj1cme_vVMnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/tmp/scores/\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzxXZ4w1VPwu",
        "outputId": "7820b341-051f-4721-d3a0-6a5c4a25c535"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['._SUCCESS.crc', 'subject=Science', 'subject=English', '_SUCCESS', 'subject=Math']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read only Math partition and display entries:"
      ],
      "metadata": {
        "id": "Knfjg-ZlVY3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_math=spark.read.parquet(\"/tmp/scores/subject=Math\")\n",
        "df_math.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IXJduxOVbZN",
        "outputId": "7aa5cd60-1c8e-425f-d686-850ddc8744f5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----+----------+\n",
            "| name|score|grade|difficulty|\n",
            "+-----+-----+-----+----------+\n",
            "| NEHA|   94|    A| Difficult|\n",
            "| RAVI|   88|    B| Difficult|\n",
            "|Meena|   93| NULL|      NULL|\n",
            "+-----+-----+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. ETL: Clean, Transform, Load\n",
        "\n",
        "Raw CSV:"
      ],
      "metadata": {
        "id": "pFhevoujWZXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=\"\"\"emp_id,name,dept,salary,bonus\n",
        "1,Arjun,IT,78000,5000\n",
        "2,Kavya,HR,62000,\n",
        "3,Sneha,Finance,55000,3000\"\"\"\n",
        "\n",
        "with open(\"employee.csv\", \"w\") as f:\n",
        "    f.write(data)"
      ],
      "metadata": {
        "id": "yAVkMM2oWgig"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data with header."
      ],
      "metadata": {
        "id": "9lG2vkk-Wx_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_emp=spark.read.csv(\"employee.csv\",header=True)\n",
        "df_emp.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXhkdxoLWsiZ",
        "outputId": "e986de2d-a856-489c-fdda-f359001da78a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+\n",
            "|emp_id| name|   dept|salary|bonus|\n",
            "+------+-----+-------+------+-----+\n",
            "|     1|Arjun|     IT| 78000| 5000|\n",
            "|     2|Kavya|     HR| 62000| NULL|\n",
            "|     3|Sneha|Finance| 55000| 3000|\n",
            "+------+-----+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill missing bonus with 2000."
      ],
      "metadata": {
        "id": "Rr8lnsb9WzhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_emp=df_emp.fillna({\"bonus\":2000})\n",
        "df_emp.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QOkuBnoW4Sc",
        "outputId": "9581e0a1-9221-4c22-e73f-c2f6900214b9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+\n",
            "|emp_id| name|   dept|salary|bonus|\n",
            "+------+-----+-------+------+-----+\n",
            "|     1|Arjun|     IT| 78000| 5000|\n",
            "|     2|Kavya|     HR| 62000| 2000|\n",
            "|     3|Sneha|Finance| 55000| 3000|\n",
            "+------+-----+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate total_ctc = salary + bonus ."
      ],
      "metadata": {
        "id": "WR3CYs3hW-IG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_emp=df_emp.withColumn(\"Total_ctc\",F.col(\"salary\")+F.col(\"bonus\"))\n",
        "df_emp.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAM1gQJ7XAlp",
        "outputId": "f04708be-f0b2-4f50-d72f-1e60806cef36"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+---------+\n",
            "|emp_id| name|   dept|salary|bonus|Total_ctc|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "|     1|Arjun|     IT| 78000| 5000|  83000.0|\n",
            "|     2|Kavya|     HR| 62000| 2000|  64000.0|\n",
            "|     3|Sneha|Finance| 55000| 3000|  58000.0|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter where total_ctc > 60,000."
      ],
      "metadata": {
        "id": "QLm9xBQbXSPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_emp.filter(F.col(\"Total_ctc\")>60000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDKR235bXVF0",
        "outputId": "c019ad68-f04d-461b-c1f4-e345798eef03"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+----+------+-----+---------+\n",
            "|emp_id| name|dept|salary|bonus|Total_ctc|\n",
            "+------+-----+----+------+-----+---------+\n",
            "|     1|Arjun|  IT| 78000| 5000|  83000.0|\n",
            "|     2|Kavya|  HR| 62000| 2000|  64000.0|\n",
            "+------+-----+----+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save final DataFrame to Parquet and JSON."
      ],
      "metadata": {
        "id": "W6GL4pTHXkkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.parquet(\"/tmp/employee.parquet\")\n",
        "df_emp.toJSON(\"Emp.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr8D8PsNXmbH",
        "outputId": "b5709149-b0a9-4a46-8a51-5adb220bd80a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MapPartitionsRDD[219] at toJavaRDD at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}