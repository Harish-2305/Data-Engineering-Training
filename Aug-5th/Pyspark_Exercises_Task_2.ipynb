{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Module 1: Setup & SparkSession Initialization**\n",
        "\n",
        "Install and configure PySpark in your local system or Colab."
      ],
      "metadata": {
        "id": "JcSMn-bcbyX9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jJB4-QP9aZx-"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"BotCampus PySpark Practice\") \\\n",
        ".master(\"local[*]\") \\\n",
        ".getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataFrame from:"
      ],
      "metadata": {
        "id": "argp03pIb-Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "(\"Anjali\", \"Bangalore\", 24),\n",
        "(\"Ravi\", \"Hyderabad\", 28),\n",
        "(\"Kavya\", \"Delhi\", 22),\n",
        "(\"Meena\", \"Chennai\", 25),\n",
        "(\"Arjun\", \"Mumbai\", 30)\n",
        "]\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "\n",
        "df_data=spark.createDataFrame(data,columns)\n",
        "df_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESDJFh2JcBXx",
        "outputId": "7a8dd4a7-66ab-4c46-c745-d4b5e571516f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---+\n",
            "|  name|     city|age|\n",
            "+------+---------+---+\n",
            "|Anjali|Bangalore| 24|\n",
            "|  Ravi|Hyderabad| 28|\n",
            "| Kavya|    Delhi| 22|\n",
            "| Meena|  Chennai| 25|\n",
            "| Arjun|   Mumbai| 30|\n",
            "+------+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show schema, explain data types, and convert to RDD."
      ],
      "metadata": {
        "id": "DACUWjc8ckWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0gGz513coQK",
        "outputId": "0a245e2f-852e-4c0b-86ef-77874c3569e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_data=df_data.rdd"
      ],
      "metadata": {
        "id": "BTobzCt6deNw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print .collect() and df.rdd.map() output."
      ],
      "metadata": {
        "id": "uRXqaAUUdmtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rdd_data.collect())\n",
        "print(df_data.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tomZdqvDdpQr",
        "outputId": "f0675911-ba9f-4c13-f567-67cfd5b1deca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(name='Anjali', city='Bangalore', age=24), Row(name='Ravi', city='Hyderabad', age=28), Row(name='Kavya', city='Delhi', age=22), Row(name='Meena', city='Chennai', age=25), Row(name='Arjun', city='Mumbai', age=30)]\n",
            "[Row(name='Anjali', city='Bangalore', age=24), Row(name='Ravi', city='Hyderabad', age=28), Row(name='Kavya', city='Delhi', age=22), Row(name='Meena', city='Chennai', age=25), Row(name='Arjun', city='Mumbai', age=30)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_data.map(lambda x:x['name']).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCsFosE4d9B2",
        "outputId": "f4ba4acd-5f81-4776-c9d9-c0ceaa011592"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Anjali', 'Ravi', 'Kavya', 'Meena', 'Arjun']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 2: RDDs & Transformations"
      ],
      "metadata": {
        "id": "L5hRttFGeSBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback = spark.sparkContext.parallelize([\n",
        "\"Ravi from Bangalore loved the delivery\",\n",
        "\"Meena from Hyderabad had a late order\",\n",
        "\"Ajay from Pune liked the service\",\n",
        "\"Anjali from Delhi faced UI issues\",\n",
        "\"Rohit from Mumbai gave positive feedback\"\n",
        "])"
      ],
      "metadata": {
        "id": "pt8Uxmr8eWYv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split each line into words ( flatMap )."
      ],
      "metadata": {
        "id": "7dXMhEcneZA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback.flatMap(lambda x:x.lower().split(\" \")).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf9Q7sNAebWx",
        "outputId": "031f1a19-d503-44fa-e69d-808221267cb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ravi',\n",
              " 'from',\n",
              " 'bangalore',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'delivery',\n",
              " 'meena',\n",
              " 'from',\n",
              " 'hyderabad',\n",
              " 'had',\n",
              " 'a',\n",
              " 'late',\n",
              " 'order',\n",
              " 'ajay',\n",
              " 'from',\n",
              " 'pune',\n",
              " 'liked',\n",
              " 'the',\n",
              " 'service',\n",
              " 'anjali',\n",
              " 'from',\n",
              " 'delhi',\n",
              " 'faced',\n",
              " 'ui',\n",
              " 'issues',\n",
              " 'rohit',\n",
              " 'from',\n",
              " 'mumbai',\n",
              " 'gave',\n",
              " 'positive',\n",
              " 'feedback']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove stop words ( from , the , etc.)."
      ],
      "metadata": {
        "id": "C7nlCV3Ee3YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set([\"from\",\"the\",\"had\",\"a\",\"an\",\"and\",\"is\",\"of\",\"to\",\"in\",\"for\"])\n",
        "feedback.flatMap(lambda x:x.lower().split(\" \")).filter(lambda x:x not in stop_words).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlesWcpLe5q1",
        "outputId": "6c4114f2-2d99-4512-d1dc-79977196ae8a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ravi',\n",
              " 'bangalore',\n",
              " 'loved',\n",
              " 'delivery',\n",
              " 'meena',\n",
              " 'hyderabad',\n",
              " 'late',\n",
              " 'order',\n",
              " 'ajay',\n",
              " 'pune',\n",
              " 'liked',\n",
              " 'service',\n",
              " 'anjali',\n",
              " 'delhi',\n",
              " 'faced',\n",
              " 'ui',\n",
              " 'issues',\n",
              " 'rohit',\n",
              " 'mumbai',\n",
              " 'gave',\n",
              " 'positive',\n",
              " 'feedback']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count each word frequency using reduceByKey ."
      ],
      "metadata": {
        "id": "sd0Up0X2fM1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback.flatMap(lambda x:x.lower().split(\" \")).map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTDEcP-EfNgj",
        "outputId": "972ceded-764e-4b08-dde6-21f15e885bde"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('from', 5),\n",
              " ('loved', 1),\n",
              " ('liked', 1),\n",
              " ('service', 1),\n",
              " ('anjali', 1),\n",
              " ('faced', 1),\n",
              " ('issues', 1),\n",
              " ('rohit', 1),\n",
              " ('mumbai', 1),\n",
              " ('positive', 1),\n",
              " ('feedback', 1),\n",
              " ('ravi', 1),\n",
              " ('bangalore', 1),\n",
              " ('the', 2),\n",
              " ('delivery', 1),\n",
              " ('meena', 1),\n",
              " ('hyderabad', 1),\n",
              " ('had', 1),\n",
              " ('a', 1),\n",
              " ('late', 1),\n",
              " ('order', 1),\n",
              " ('ajay', 1),\n",
              " ('pune', 1),\n",
              " ('delhi', 1),\n",
              " ('ui', 1),\n",
              " ('gave', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find top 3 most frequent non-stop words."
      ],
      "metadata": {
        "id": "hDFlmS0-fyJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback.flatMap(lambda x:x.lower().split(\" \")).filter(lambda x:x not in stop_words).map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y).sortBy(lambda x:x[1],ascending=False).take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCzUKAYLf0t9",
        "outputId": "ce40f9eb-8a32-4563-d037-0726c4fa369d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('loved', 1), ('liked', 1), ('service', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Module 3: DataFrames & Transformation (With Joins)**"
      ],
      "metadata": {
        "id": "7kCDrWDEgA3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "students = [\n",
        "(\"Amit\", \"10-A\", 89),\n",
        "(\"Kavya\", \"10-B\", 92),\n",
        "(\"Anjali\", \"10-A\", 78),\n",
        "(\"Rohit\", \"10-B\", 85),\n",
        "(\"Sneha\", \"10-C\", 80)\n",
        "]\n",
        "columns = [\"name\", \"section\", \"marks\"]\n",
        "df_students=spark.createDataFrame(students,columns)\n",
        "df_students.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvl908FQgdP8",
        "outputId": "50c5fb83-50cc-4dc4-e47e-3a0dc9fe13cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+\n",
            "|  name|section|marks|\n",
            "+------+-------+-----+\n",
            "|  Amit|   10-A|   89|\n",
            "| Kavya|   10-B|   92|\n",
            "|Anjali|   10-A|   78|\n",
            "| Rohit|   10-B|   85|\n",
            "| Sneha|   10-C|   80|\n",
            "+------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attendance = [\n",
        "(\"Amit\", 24),\n",
        "(\"Kavya\", 22),\n",
        "(\"Anjali\", 20),\n",
        "(\"Rohit\", 25),\n",
        "(\"Sneha\", 19)\n",
        "]\n",
        "columns2 = [\"name\", \"days_present\"]\n",
        "df_attendance=spark.createDataFrame(attendance,columns2)\n",
        "df_attendance.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VatI_n0hiN6q",
        "outputId": "476379b3-ae5a-4838-e10d-8d4028bb35ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+\n",
            "|  name|days_present|\n",
            "+------+------------+\n",
            "|  Amit|          24|\n",
            "| Kavya|          22|\n",
            "|Anjali|          20|\n",
            "| Rohit|          25|\n",
            "| Sneha|          19|\n",
            "+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join both DataFrames on name ."
      ],
      "metadata": {
        "id": "xfpcf8K7iTTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged=df_students.join(df_attendance,on='name',how='inner')\n",
        "df_merged.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP6sVJEbiVBQ",
        "outputId": "01c0f582-3273-4ffc-ad05-43a00ddeeb74"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+\n",
            "|  name|section|marks|days_present|\n",
            "+------+-------+-----+------------+\n",
            "|  Amit|   10-A|   89|          24|\n",
            "|Anjali|   10-A|   78|          20|\n",
            "| Kavya|   10-B|   92|          22|\n",
            "| Rohit|   10-B|   85|          25|\n",
            "| Sneha|   10-C|   80|          19|\n",
            "+------+-------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new column: attendance_rate = days_present / 25"
      ],
      "metadata": {
        "id": "X-grK7Uki2w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged=df_merged.withColumn('attendance_rate',(df_merged['days_present']/25)*100)\n",
        "df_merged.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DflLhlK7i47v",
        "outputId": "e4289569-485b-4ed8-c683-221a0a0eef09"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+---------------+\n",
            "|  name|section|marks|days_present|attendance_rate|\n",
            "+------+-------+-----+------------+---------------+\n",
            "|  Amit|   10-A|   89|          24|           96.0|\n",
            "|Anjali|   10-A|   78|          20|           80.0|\n",
            "| Kavya|   10-B|   92|          22|           88.0|\n",
            "| Rohit|   10-B|   85|          25|          100.0|\n",
            "| Sneha|   10-C|   80|          19|           76.0|\n",
            "+------+-------+-----+------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grade students using when :\n",
        "A: >90, B: 80–90, C: <80."
      ],
      "metadata": {
        "id": "A9IkMLBWjDin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "df_students=df_students.withColumn('grade',F.when(df_students['marks']>90,'A').when((df_students['marks']>=80) & (df_students['marks']<=90),'B').otherwise('C'))\n",
        "df_students.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmwu-cedjNM3",
        "outputId": "2561b598-9292-4b0c-873a-f9f049b1f9a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-----+\n",
            "|  name|section|marks|grade|\n",
            "+------+-------+-----+-----+\n",
            "|  Amit|   10-A|   89|    B|\n",
            "| Kavya|   10-B|   92|    A|\n",
            "|Anjali|   10-A|   78|    C|\n",
            "| Rohit|   10-B|   85|    B|\n",
            "| Sneha|   10-C|   80|    B|\n",
            "+------+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter students with good grades but poor attendance (<80%)."
      ],
      "metadata": {
        "id": "wclGS3Mgjcb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged=df_merged.withColumn('grade',F.when(df_merged['marks']>90,'A').when((df_merged['marks']>=80) & (df_merged['marks']<=90),'B').otherwise('C'))\n",
        "\n",
        "df_merged.filter((df_merged['grade'].isin(['A','B'])) & (df_merged['attendance_rate']<80)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ5d6C2mjeK0",
        "outputId": "656faed0-f2cf-4e7d-a58a-de18591bcfaf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+------------+---------------+-----+\n",
            "| name|section|marks|days_present|attendance_rate|grade|\n",
            "+-----+-------+-----+------------+---------------+-----+\n",
            "|Sneha|   10-C|   80|          19|           76.0|    B|\n",
            "+-----+-------+-----+------------+---------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 4: Ingest CSV & JSON, Save to Parquet\n",
        "\n",
        "1. Ingest CSV:"
      ],
      "metadata": {
        "id": "qnJN8ynYj3v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=\"\"\"emp_id,name,dept,city,salary\n",
        "101,Anil,IT,Bangalore,80000\n",
        "102,Kiran,HR,Mumbai,65000\n",
        "103,Deepa,Finance,Chennai,72000\"\"\"\n",
        "\n",
        "with open ('employee1.csv','w') as f:\n",
        "  f.write(data)"
      ],
      "metadata": {
        "id": "k6h-Oi9cj6Y-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ingest JSON:"
      ],
      "metadata": {
        "id": "iCZMHnO7kYFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "data={\n",
        "\"id\": 201,\n",
        "\"name\": \"Nandini\",\n",
        "\"contact\": {\n",
        "\"email\": \"nandi@example.com\",\n",
        "\"city\": \"Hyderabad\"\n",
        "},\n",
        "\"skills\": [\"Python\", \"Spark\", \"SQL\"]\n",
        "}\n",
        "\n",
        "\n",
        "with open ('employee2.json','w') as f:\n",
        "  json.dump(data,f)\n"
      ],
      "metadata": {
        "id": "m09z-iArkbgQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read both formats into DataFrames."
      ],
      "metadata": {
        "id": "NfRSf1Trkur6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv=spark.read.csv('employee1.csv',header=True,inferSchema=True)\n",
        "df_csv.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0lohT-nkzjO",
        "outputId": "6f254deb-9557-49d9-c67e-d2553d7c3897"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+---------+------+\n",
            "|emp_id| name|   dept|     city|salary|\n",
            "+------+-----+-------+---------+------+\n",
            "|   101| Anil|     IT|Bangalore| 80000|\n",
            "|   102|Kiran|     HR|   Mumbai| 65000|\n",
            "|   103|Deepa|Finance|  Chennai| 72000|\n",
            "+------+-----+-------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_json=spark.read.json('employee2.json')\n",
        "df_json.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MnwKnBPmB2s",
        "outputId": "78484103-9881-40b3-cae8-a76dd1eaf1eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---+-------+--------------------+\n",
            "|             contact| id|   name|              skills|\n",
            "+--------------------+---+-------+--------------------+\n",
            "|{Hyderabad, nandi...|201|Nandini|[Python, Spark, SQL]|\n",
            "+--------------------+---+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten nested JSON using select , col , alias , explode ."
      ],
      "metadata": {
        "id": "3C3IOgsSmLHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "df_flat=df_json.select(F.col('id'),F.col('name'),F.col('contact.email').alias('email'),F.col('contact.city').alias('city'),F.explode(F.col('skills')).alias('skill'))\n",
        "df_flat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Klu4MjdmNsA",
        "outputId": "0412556b-65b6-4196-c62f-a6a8e4c2cf71"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+-----------------+---------+------+\n",
            "| id|   name|            email|     city| skill|\n",
            "+---+-------+-----------------+---------+------+\n",
            "|201|Nandini|nandi@example.com|Hyderabad|Python|\n",
            "|201|Nandini|nandi@example.com|Hyderabad| Spark|\n",
            "|201|Nandini|nandi@example.com|Hyderabad|   SQL|\n",
            "+---+-------+-----------------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save both as Parquet files partitioned by city."
      ],
      "metadata": {
        "id": "HBQYPmn4nBV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv.write.partitionBy('city').parquet('/temp/output/employee1.parquet')\n",
        "df_flat.write.partitionBy('city').parquet('/temp/output/employee2.parquet')"
      ],
      "metadata": {
        "id": "IHqV1MWpmwBH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Module 5: Spark SQL with Temp Views**\n",
        "\n",
        "Register the students DataFrame as students_view ."
      ],
      "metadata": {
        "id": "0HNg5xE3nYy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_students.createOrReplaceTempView('students_view')"
      ],
      "metadata": {
        "id": "avNT7MxvnsxT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Average marks per section"
      ],
      "metadata": {
        "id": "YYk5VknspM3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select section,avg(marks) from students_view group by section\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owAqGtFNpPCY",
        "outputId": "b8d2ca37-f7bd-4606-a2e7-f50690987544"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+\n",
            "|section|avg(marks)|\n",
            "+-------+----------+\n",
            "|   10-A|      83.5|\n",
            "|   10-B|      88.5|\n",
            "|   10-C|      80.0|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Top scorer in each section"
      ],
      "metadata": {
        "id": "fOVguXeuphar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select s1.section,s1.name,s1.marks from students_view s1 where s1.marks=(select max(s2.marks) from students_view s2 where s2.section=s1.section )\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM5Zp18LqC7y",
        "outputId": "cbf548f7-8e48-46be-f10f-ccd917d0d7c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+-----+\n",
            "|section| name|marks|\n",
            "+-------+-----+-----+\n",
            "|   10-B|Kavya|   92|\n",
            "|   10-A| Amit|   89|\n",
            "|   10-C|Sneha|   80|\n",
            "+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Count of students in each grade category"
      ],
      "metadata": {
        "id": "BFXYm1qsqGXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select grade,count(*) from students_view group by grade\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWhDH83LqnPL",
        "outputId": "6cb51618-e9e9-48e4-84fc-1feb1c4cf67d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+\n",
            "|grade|count(1)|\n",
            "+-----+--------+\n",
            "|    B|       3|\n",
            "|    A|       1|\n",
            "|    C|       1|\n",
            "+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Students with marks above class average"
      ],
      "metadata": {
        "id": "g5rYZhyoqyLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from students_view where marks>(select avg(marks) as AVG_mark from students_view)\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZZlgzWTq0jB",
        "outputId": "abca7d02-f9d8-46cb-ce5a-d9801f3ce6c8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+-----+\n",
            "| name|section|marks|grade|\n",
            "+-----+-------+-----+-----+\n",
            "| Amit|   10-A|   89|    B|\n",
            "|Kavya|   10-B|   92|    A|\n",
            "|Rohit|   10-B|   85|    B|\n",
            "+-----+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) Attendance-adjusted performance"
      ],
      "metadata": {
        "id": "55CGBzH4sQMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.createOrReplaceTempView('merged_view')\n",
        "spark.sql(\"select name,section,marks,days_present,(marks*(days_present/25)) as adjusted_marks from merged_view\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNs3qR94sUIH",
        "outputId": "133bc5b7-3751-494c-823d-bc3945b9720e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+------------------+\n",
            "|  name|section|marks|days_present|    adjusted_marks|\n",
            "+------+-------+-----+------------+------------------+\n",
            "|  Amit|   10-A|   89|          24|             85.44|\n",
            "|Anjali|   10-A|   78|          20|62.400000000000006|\n",
            "| Kavya|   10-B|   92|          22|             80.96|\n",
            "| Rohit|   10-B|   85|          25|              85.0|\n",
            "| Sneha|   10-C|   80|          19|              60.8|\n",
            "+------+-------+-----+------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Module 6: Partitioned Data & Incremental Loading**\n",
        "\n",
        "Step 1: Full Load"
      ],
      "metadata": {
        "id": "ZwN_hGaZtPbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_students.write.partitionBy(\"section\").parquet(\"output/students/\")"
      ],
      "metadata": {
        "id": "B6D_yNvJtST9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Incremental Load"
      ],
      "metadata": {
        "id": "pT61JgiGtYY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incremental = [(\"Tejas\", \"10-A\", 91)]\n",
        "df_inc = spark.createDataFrame(incremental, [\"name\", \"section\", \"marks\"])\n",
        "df_inc.write.mode(\"append\").partitionBy(\"section\").parquet(\"output/students/\")"
      ],
      "metadata": {
        "id": "jVkgwKghtb3V"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List files in output/students/ using Python."
      ],
      "metadata": {
        "id": "v2W2c1L9tpVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('output/students'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XAaXFxytrTV",
        "outputId": "656bf211-e91d-4c46-9033-c312e2736b8e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['._SUCCESS.crc', 'section=10-A', 'section=10-B', '_SUCCESS', 'section=10-C']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read only partition 10-A and list students."
      ],
      "metadata": {
        "id": "Q9F6VHl9txOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_10_A=spark.read.parquet('output/students/section=10-A')\n",
        "df_10_A.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8-clKsqtzYf",
        "outputId": "cc842cd0-2286-417e-c847-dd9015243a58"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-----+\n",
            "|  name|marks|grade|\n",
            "+------+-----+-----+\n",
            "|Anjali|   78|    C|\n",
            "|  Amit|   89|    B|\n",
            "| Tejas|   91| NULL|\n",
            "+------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare before/after counts for section 10-A ."
      ],
      "metadata": {
        "id": "kA4rPbjGuKCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_10_A.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvYOegl1ugBM",
        "outputId": "27b2a3da-ef24-438b-eee0-d13f46e5324d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_students.filter(F.col(\"section\") == \"10-A\").count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM0fHI3YuKye",
        "outputId": "8b3587a5-35df-4c8d-c4fc-c1734b0a39f5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Module 7: ETL Pipeline – End to End**\n",
        "\n",
        "Given Raw Data (CSV):"
      ],
      "metadata": {
        "id": "W-6oG8uLuw7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=\"\"\"emp_id,name,dept,salary,bonus\n",
        "1,Arjun,IT,75000,5000\n",
        "2,Kavya,HR,62000,\n",
        "3,Sneha,Finance,68000,4000\n",
        "4,Ramesh,Sales,58000,\"\"\"\n",
        "\n",
        "with open ('employees.csv','w') as f:\n",
        "  f.write(data)"
      ],
      "metadata": {
        "id": "mALg9D4gu1pu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load CSV with inferred schema."
      ],
      "metadata": {
        "id": "09pPkmOivYiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_employees=spark.read.csv('employees.csv',header=True,inferSchema=True)\n",
        "df_employees.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDReKC52vRi4",
        "outputId": "af481a93-0242-4d95-b906-fd1428534d39"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+\n",
            "|emp_id|  name|   dept|salary|bonus|\n",
            "+------+------+-------+------+-----+\n",
            "|     1| Arjun|     IT| 75000| 5000|\n",
            "|     2| Kavya|     HR| 62000| NULL|\n",
            "|     3| Sneha|Finance| 68000| 4000|\n",
            "|     4|Ramesh|  Sales| 58000| NULL|\n",
            "+------+------+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill null bonuses with 2000 ."
      ],
      "metadata": {
        "id": "0X6PdnD2vbR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_employees=df_employees.fillna({'bonus':2000})\n",
        "df_employees.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q0TP60BvfyP",
        "outputId": "ac6e8017-6cac-4bd4-98f6-e5e321fa01a8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+\n",
            "|emp_id|  name|   dept|salary|bonus|\n",
            "+------+------+-------+------+-----+\n",
            "|     1| Arjun|     IT| 75000| 5000|\n",
            "|     2| Kavya|     HR| 62000| 2000|\n",
            "|     3| Sneha|Finance| 68000| 4000|\n",
            "|     4|Ramesh|  Sales| 58000| 2000|\n",
            "+------+------+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create total_ctc = salary + bonus ."
      ],
      "metadata": {
        "id": "6lLyB-pbvoXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_employees=df_employees.withColumn('total_ctc',F.col('salary')+F.col('bonus'))\n",
        "df_employees.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXJC-nttvreK",
        "outputId": "8c206db0-0295-4c88-b1b0-6794c94bbffd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+---------+\n",
            "|emp_id|  name|   dept|salary|bonus|total_ctc|\n",
            "+------+------+-------+------+-----+---------+\n",
            "|     1| Arjun|     IT| 75000| 5000|    80000|\n",
            "|     2| Kavya|     HR| 62000| 2000|    64000|\n",
            "|     3| Sneha|Finance| 68000| 4000|    72000|\n",
            "|     4|Ramesh|  Sales| 58000| 2000|    60000|\n",
            "+------+------+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter employees with total_ctc > 65000"
      ],
      "metadata": {
        "id": "h3LGOOBAv4e-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_employees.filter(F.col('total_ctc')>65000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqWFEIyfv6N4",
        "outputId": "4d5bd8e8-5680-4508-fe4a-f0272349aa5e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+---------+\n",
            "|emp_id| name|   dept|salary|bonus|total_ctc|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "|     1|Arjun|     IT| 75000| 5000|    80000|\n",
            "|     3|Sneha|Finance| 68000| 4000|    72000|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save result in:\n",
        "\n",
        "JSON format.\n",
        "\n",
        "Parquet format partitioned by department."
      ],
      "metadata": {
        "id": "oxco-umhwELx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_employees.write.json('employees.json')\n",
        "df_employees.write.partitionBy('dept').parquet('employees.parquet')"
      ],
      "metadata": {
        "id": "elru-Be0wIdU"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}